{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline dice score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(baseline_seg, gt_seg, target_class):\n",
    "    \"\"\"\n",
    "    Compute the Dice score for a specific class.\n",
    "    \n",
    "    Parameters:\n",
    "    - res_seg: np.array, predicted segmentation\n",
    "    - gt_seg: np.array, ground truth segmentation\n",
    "    - target_class: int, the class for which the Dice score is computed\n",
    "    \n",
    "    Returns:\n",
    "    - dice: float, Dice score for the target class\n",
    "    \"\"\"\n",
    "    # Create binary masks for the target class\n",
    "    baseline_mask = (baseline_seg == target_class)\n",
    "    gt_mask = (gt_seg == target_class)\n",
    "    \n",
    "    # Compute intersection and union\n",
    "    intersection = np.sum(baseline_mask & gt_mask)\n",
    "    total_pixels = np.sum(baseline_mask) + np.sum(gt_mask)\n",
    "    \n",
    "    # Compute Dice score\n",
    "    if total_pixels == 0:  # Avoid division by zero\n",
    "        return 1.0 if np.sum(gt_mask) == 0 else 0.0\n",
    "    \n",
    "    dice = (2 * intersection) / total_pixels\n",
    "    return dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Import from different folder\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_preprocess_dir = os.path.join(parent_dir, \"DataPreprocess\")\n",
    "\n",
    "sys.path.append(data_preprocess_dir)\n",
    "from main_preprocess import load_nifti_convert_to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_path = '/Users/bruger/Desktop/Bachelor/resampled_lung_pilot_data'\n",
    "cropped_lung_ct_path = data_path + '/cropped_lungs_ct/*.nii.gz'\n",
    "cropped_lung_ct_paths = glob.glob(cropped_lung_ct_path)\n",
    "\n",
    "cropped_lung_gt_path = data_path + '/cropped_lungs_seg/*.nii.gz'\n",
    "cropped_lung_gt_paths = glob.glob(cropped_lung_gt_path)\n",
    "\n",
    "output_dir = data_path + \"/numpy_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = []\n",
    "# for path in cropped_lung_ct_paths:\n",
    "#     arr = load_nifti_convert_to_numpy(input_path=path).flatten()\n",
    "#     baseline_seg = np.where(\n",
    "#     arr == -10000, 0,  # If the value is -10000, classify as 0\n",
    "#     np.where(\n",
    "#         (arr >= -720) & (arr <= -300), 2,  # If within the range [-720, -300], classify as 2\n",
    "#         1  # Otherwise, classify as 1\n",
    "#     )\n",
    "# )\n",
    "#     patient_id = os.path.basename(path)[7:10]\n",
    "\n",
    "#     np.save(os.path.join(output_dir, f\"patient_{patient_id}_attenuation.npy\"), arr)\n",
    "#     np.save(os.path.join(output_dir, f\"patient_{patient_id}_baseline_seg.npy\"), baseline_seg)\n",
    "\n",
    "#     new_row = {\n",
    "#         'attenuation': arr,\n",
    "#         'res_seg': baseline_seg,\n",
    "#         'patient': patient_id,\n",
    "#         'label': 'w_ggo' if int(patient_id) < 14 else 'wo_ggo',\n",
    "#     }\n",
    "#     rows.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# gt_rows = []\n",
    "# for path in cropped_lung_gt_paths:\n",
    "#     patient_id = os.path.basename(path)[8:11]\n",
    "#     output_file = os.path.join(output_dir, f\"patient_{patient_id}_gt_seg.npy\")\n",
    "    \n",
    "#     # Check if the output file already exists\n",
    "#     if os.path.exists(output_file):\n",
    "#         print(f\"Output file for patient {patient_id} already exists. Skipping...\")\n",
    "#         continue\n",
    "    \n",
    "#     # Process the file and save it\n",
    "#     gt_seg = load_nifti_convert_to_numpy(input_path=path).flatten()\n",
    "#     np.save(output_file, gt_seg)\n",
    "    \n",
    "#     # Prepare the metadata\n",
    "#     new_gt_row = {\n",
    "#         'gt_seg': gt_seg,\n",
    "#         'patient': patient_id,\n",
    "#         'label': 'w_ggo' if int(patient_id) < 14 else 'wo_ggo',\n",
    "#     }\n",
    "#     print(patient_id)\n",
    "#     gt_rows.append(new_gt_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "024 gt\n",
      "013 gt\n",
      "014 attenuation\n",
      "008 baseline\n",
      "026 attenuation\n",
      "022 baseline\n",
      "002 gt\n",
      "003 baseline\n",
      "002 attenuation\n",
      "007 baseline\n",
      "005 attenuation\n",
      "007 gt\n",
      "021 attenuation\n",
      "018 baseline\n",
      "026 baseline\n",
      "021 gt\n",
      "013 attenuation\n",
      "013 baseline\n",
      "009 baseline\n",
      "004 attenuation\n",
      "020 attenuation\n",
      "011 gt\n",
      "026 gt\n",
      "000 gt\n",
      "012 attenuation\n",
      "002 baseline\n",
      "023 baseline\n",
      "019 baseline\n",
      "027 baseline\n",
      "005 gt\n",
      "019 gt\n",
      "006 baseline\n",
      "008 gt\n",
      "012 baseline\n",
      "027 attenuation\n",
      "003 attenuation\n",
      "023 gt\n",
      "014 gt\n",
      "022 attenuation\n",
      "001 baseline\n",
      "006 gt\n",
      "020 baseline\n",
      "006 attenuation\n",
      "009 attenuation\n",
      "020 gt\n",
      "010 attenuation\n",
      "025 gt\n",
      "012 gt\n",
      "011 baseline\n",
      "001 attenuation\n",
      "024 baseline\n",
      "005 baseline\n",
      "003 gt\n",
      "025 attenuation\n",
      "018 attenuation\n",
      "004 gt\n",
      "021 baseline\n",
      "000 baseline\n",
      "018 gt\n",
      "014 baseline\n",
      "000 attenuation\n",
      "009 gt\n",
      "024 attenuation\n",
      "019 attenuation\n",
      "022 gt\n",
      "023 attenuation\n",
      "010 baseline\n",
      "007 attenuation\n"
     ]
    }
   ],
   "source": [
    "# Directory containing the numpy files\n",
    "data_dir = output_dir\n",
    "\n",
    "# Initialize a dictionary to store data\n",
    "data = {'patient_id': [], 'baseline_seg': [], 'gt_seg': []}\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith('.npy'):\n",
    "        # Extract patient ID and type of file from the filename\n",
    "        parts = file.split('_')\n",
    "        patient_id = parts[1]  # Assuming format is 'patient_XXX_...'\n",
    "        file_type = parts[2].split('.')[0]  # Extract 'baseline', or 'gt_seg'\n",
    "\n",
    "        # Load the numpy file\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        data_array = np.load(file_path)\n",
    "\n",
    "        # Check if patient_id is already in data\n",
    "        if patient_id not in data['patient_id']:\n",
    "            data['patient_id'].append(patient_id)\n",
    "            data['baseline_seg'].append(None)\n",
    "            data['gt_seg'].append(None)\n",
    "\n",
    "        # Update the respective field based on the file type\n",
    "        idx = data['patient_id'].index(patient_id)\n",
    "        if file_type == 'baseline':\n",
    "            data['baseline_seg'][idx] = data_array\n",
    "        elif file_type == 'gt':\n",
    "            data['gt_seg'][idx] = data_array\n",
    "        print(patient_id, file_type)\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "df = pd.DataFrame(data).sort_values('patient_id')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m base, gt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaseline_seg\u001b[39m\u001b[38;5;124m'\u001b[39m], df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_seg\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(base), \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "for base, gt in zip(df['baseline_seg'], df['gt_seg']):\n",
    "    print(len(base), len(gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = 2\n",
    "\n",
    "dice_scores = df.apply(\n",
    "    lambda row: dice_score(baseline_seg=row['baseline_seg'], gt_seg=row['gt_seg'], target_class=target_class), \n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
