{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline dice score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(baseline_seg, gt_seg, target_class):\n",
    "    \"\"\"\n",
    "    Compute the Dice score for a specific class.\n",
    "    \n",
    "    Parameters:\n",
    "    - res_seg: np.array, predicted segmentation\n",
    "    - gt_seg: np.array, ground truth segmentation\n",
    "    - target_class: int, the class for which the Dice score is computed\n",
    "    \n",
    "    Returns:\n",
    "    - dice: float, Dice score for the target class\n",
    "    \"\"\"\n",
    "    # Create binary masks for the target class\n",
    "    baseline_mask = (baseline_seg == target_class)\n",
    "    gt_mask = (gt_seg == target_class)\n",
    "    \n",
    "    # Compute intersection and union\n",
    "    intersection = np.sum(baseline_mask & gt_mask)\n",
    "    total_pixels = np.sum(baseline_mask) + np.sum(gt_mask)\n",
    "    \n",
    "    # Compute Dice score\n",
    "    if total_pixels == 0:  # Avoid division by zero\n",
    "        print('it is zero')\n",
    "        return 1.0 if np.sum(gt_mask) == 0 else 0.0\n",
    "    \n",
    "    dice = (2 * intersection) / total_pixels\n",
    "    return dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Import from different folder\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "data_preprocess_dir = os.path.join(parent_dir, \"DataPreprocess\")\n",
    "\n",
    "sys.path.append(data_preprocess_dir)\n",
    "from main_preprocess import load_nifti_convert_to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_path = '/Users/bruger/Desktop/Bachelor/resampled_lung_pilot_data'\n",
    "cropped_lung_ct_path = data_path + '/cropped_lungs_ct/*.nii.gz'\n",
    "cropped_lung_ct_paths = glob.glob(cropped_lung_ct_path)\n",
    "\n",
    "cropped_lung_gt_path = data_path + '/cropped_lungs_seg/*.nii.gz'\n",
    "cropped_lung_gt_paths = glob.glob(cropped_lung_gt_path)\n",
    "\n",
    "output_dir = data_path + \"/numpy_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows = []\n",
    "# for path in cropped_lung_ct_paths:\n",
    "#     arr = load_nifti_convert_to_numpy(input_path=path).flatten()\n",
    "#     baseline_seg = np.where(\n",
    "#     arr == -10000, 0,  # If the value is -10000, classify as 0\n",
    "#     np.where(\n",
    "#         (arr >= -720) & (arr <= -300), 2,  # If within the range [-720, -300], classify as 2\n",
    "#         1  # Otherwise, classify as 1\n",
    "#     )\n",
    "# )\n",
    "#     patient_id = os.path.basename(path)[7:10]\n",
    "\n",
    "#     np.save(os.path.join(output_dir, f\"patient_{patient_id}_attenuation.npy\"), arr)\n",
    "#     np.save(os.path.join(output_dir, f\"patient_{patient_id}_baseline_seg.npy\"), baseline_seg)\n",
    "\n",
    "#     new_row = {\n",
    "#         'attenuation': arr,\n",
    "#         'res_seg': baseline_seg,\n",
    "#         'patient': patient_id,\n",
    "#         'label': 'w_ggo' if int(patient_id) < 14 else 'wo_ggo',\n",
    "#     }\n",
    "#     rows.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_rows = []\n",
    "# for path in cropped_lung_gt_paths:\n",
    "#     patient_id = os.path.basename(path)[8:11]\n",
    "#     output_file = os.path.join(output_dir, f\"patient_{patient_id}_gt_seg.npy\")\n",
    "    \n",
    "#     # Check if the output file already exists\n",
    "#     if os.path.exists(output_file):\n",
    "#         print(f\"Output file for patient {patient_id} already exists. Skipping...\")\n",
    "#         continue\n",
    "    \n",
    "#     # Process the file and save it\n",
    "#     gt_seg = load_nifti_convert_to_numpy(input_path=path).flatten()\n",
    "#     np.save(output_file, gt_seg)\n",
    "    \n",
    "#     # Prepare the metadata\n",
    "#     new_gt_row = {\n",
    "#         'gt_seg': gt_seg,\n",
    "#         'patient': patient_id,\n",
    "#         'label': 'w_ggo' if int(patient_id) < 14 else 'wo_ggo',\n",
    "#     }\n",
    "#     print(patient_id)\n",
    "#     gt_rows.append(new_gt_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Directory containing the numpy files\n",
    "# data_dir = output_dir\n",
    "\n",
    "# target_class = 2\n",
    "\n",
    "# dice_score(baseline_seg=row['baseline_seg'], gt_seg=row['gt_seg'], target_class=target_class)\n",
    "\n",
    "# # Initialize a dictionary to store data\n",
    "# data = {'patient_id': [], 'baseline_seg': [], 'gt_seg': []}\n",
    "\n",
    "# # Loop through all files in the directory\n",
    "# for file in os.listdir(data_dir):\n",
    "#     print('new')\n",
    "#     if file.endswith('.npy'):\n",
    "#         # Extract patient ID and type of file from the filename\n",
    "#         parts = file.split('_')\n",
    "#         patient_id = parts[1]  # Assuming format is 'patient_XXX_...'\n",
    "#         file_type = parts[2].split('.')[0]  # Extract 'baseline', or 'gt_seg'\n",
    "#         if file_type == 'attenuation':\n",
    "#             continue\n",
    "\n",
    "#         # Load the numpy file\n",
    "#         file_path = os.path.join(data_dir, file)\n",
    "#         data_array = np.load(file_path)\n",
    "\n",
    "#         # Check if patient_id is already in data\n",
    "#         if patient_id not in data['patient_id']:\n",
    "#             data['patient_id'].append(patient_id)\n",
    "#             data['baseline_seg'].append(None)\n",
    "#             data['gt_seg'].append(None)\n",
    "\n",
    "#         # Update the respective field based on the file type\n",
    "#         idx = data['patient_id'].index(patient_id)\n",
    "#         if file_type == 'baseline':\n",
    "#             data['baseline_seg'][idx] = data_array\n",
    "#         elif file_type == 'gt':\n",
    "#             data['gt_seg'][idx] = data_array\n",
    "#         print(patient_id, file_type)\n",
    "\n",
    "# # Convert the dictionary to a pandas DataFrame\n",
    "# df = pd.DataFrame(data).sort_values('patient_id')\n",
    "# df = df.reset_index(drop=True)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the numpy files\n",
    "data_dir = output_dir\n",
    "\n",
    "# Initialize a list to store results\n",
    "dice_scores = []\n",
    "\n",
    "# Loop through all patient IDs\n",
    "processed_patients = set()\n",
    "\n",
    "for file in os.listdir(data_dir):\n",
    "    if not file.endswith('.npy'):\n",
    "        continue\n",
    "\n",
    "    # Extract patient ID and type of file from the filename\n",
    "    parts = file.split('_')\n",
    "    patient_id = parts[1]  # Assuming format is 'patient_XXX_...'\n",
    "    file_type = parts[2].split('.')[0]  # Extract 'baseline', or 'gt_seg'\n",
    "\n",
    "    # Skip if attenuation file\n",
    "    if file_type == 'attenuation':\n",
    "        continue\n",
    "\n",
    "    # Load the current file\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    data_array = np.load(file_path)\n",
    "\n",
    "    # Check if the patient has already been processed\n",
    "    if patient_id in processed_patients:\n",
    "        continue\n",
    "\n",
    "    # Try to find the corresponding baseline and gt files\n",
    "    baseline_file = f'patient_{patient_id}_baseline_seg.npy'\n",
    "    gt_file = f'patient_{patient_id}_gt_seg.npy'\n",
    "\n",
    "    baseline_path = os.path.join(data_dir, baseline_file)\n",
    "    gt_path = os.path.join(data_dir, gt_file)\n",
    "\n",
    "    # Check if both files exist\n",
    "    if os.path.exists(baseline_path) and os.path.exists(gt_path):\n",
    "        # Load both arrays\n",
    "        baseline_seg = np.load(baseline_path)\n",
    "        gt_seg = np.load(gt_path)\n",
    "\n",
    "        # Calculate Dice score for the target class\n",
    "        target_class = 2\n",
    "        dice = dice_score(baseline_seg, gt_seg, target_class)\n",
    "\n",
    "        # Append results to the list\n",
    "        dice_scores.append({'patient_id': patient_id, 'dice_score': dice})\n",
    "\n",
    "        print(f\"Processed patient {patient_id} with Dice score: {dice}\")\n",
    "    else:\n",
    "        print(\"Failed for patient {patient_id}\")\n",
    "\n",
    "    # Mark the patient as processed\n",
    "    processed_patients.add(patient_id)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patient_id  dice_score\n",
      "0         000         0.0\n",
      "1         001         0.0\n",
      "2         002         0.0\n",
      "3         003         0.0\n",
      "4         004         0.0\n",
      "5         005         0.0\n",
      "6         006         0.0\n",
      "7         007         0.0\n",
      "8         008         0.0\n",
      "9         009         0.0\n",
      "10        010         0.0\n",
      "11        011         0.0\n",
      "12        012         0.0\n",
      "13        013         0.0\n",
      "14        014         0.0\n"
     ]
    }
   ],
   "source": [
    "# Convert results to a DataFrame\n",
    "df_dice = pd.DataFrame(dice_scores).sort_values('patient_id')\n",
    "df_dice = df_dice.reset_index(drop=True)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_dice)\n",
    "\n",
    "# Optionally, save results to a CSV file\n",
    "df_dice.to_csv(os.path.join(data_dir, 'dice_scores.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
